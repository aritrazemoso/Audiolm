<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Recording and Transcription</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet">
</head>

<body>
    <div class="container py-5">
        <h1 class="text-center mb-4">Audio Recording and Transcription</h1>

        <!-- Recording Buttons -->
        <div class="d-flex justify-content-center mb-4">
            <button id="startRecording" class="btn btn-primary me-2" onclick="startRecording()">Start Recording</button>
            <button id="stopRecording" class="btn btn-danger" onclick="stopRecording()" disabled>Stop Recording</button>
        </div>

        <!-- Recording Skeleton -->
        <div id="recordingSkeleton" class="text-center py-5" style="display: none;">
            <div class="spinner-border text-primary" role="status">
                <span class="visually-hidden">Recording...</span>
            </div>
            <p class="mt-3">Recording in progress...</p>
        </div>

        <!-- Recorded Audio Section -->
        <div class="card mb-4" id="recordedAudioContainer" style="display: none;">
            <div class="card-body">
                <h5 class="card-title">Recorded Audio</h5>
                <audio id="recordedAudioPlayer" controls class="w-100">
                    <source id="recordedAudioSource" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
            </div>
        </div>

        <!-- Transcription Skeleton -->
        <div id="transcriptionSkeleton" class="bg-light p-3 rounded mb-4" style="display: none;">
            <div class="placeholder-glow">
                <span class="placeholder col-12"></span>
                <span class="placeholder col-10"></span>
                <span class="placeholder col-8"></span>
            </div>
        </div>

        <!-- Transcription Section -->
        <div class="card mb-4">
            <div class="card-body">
                <h5 class="card-title">Transcription</h5>
                <pre id="transcription" class="bg-light p-3 rounded"></pre>
                <button id="generateAudio" class="btn btn-success mt-3" onclick="generateAudio()" disabled>Ask
                    Chatgpt</button>
            </div>
        </div>

        <!-- Query and Generated Audio Section -->
        <div class="card" id="chagpt_audio" style="display: none;">
            <div class="card-body">
                <div id="queryText" class="mb-3"><strong>Query:</strong></div>
                <audio id="audioPlayer" controls autoplay class="w-100">
                </audio>
            </div>
        </div>
    </div>

    <!-- Bootstrap JS and dependencies -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js"></script>

    <!-- JavaScript -->
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let transcriptionText = "";
        let websocket;
        let audioContext;
        let processor;
        let input;



        function initWebSocket() {
            if (!websocket || websocket.readyState === WebSocket.CLOSED) {
                websocket = new WebSocket("ws://localhost:8000/ws/audio");
                websocket.onmessage = function (event) {
                    document.getElementById("transcription").innerText = document.getElementById("transcription").innerText + " " + event.data;
                    transcriptionText = document.getElementById("transcription").innerText;
                };
                websocket.onclose = function () {
                    console.log("WebSocket closed. Retrying in 2 seconds...");
                    setTimeout(initWebSocket, 2000);
                };
            }
        }

        function reset_state() {
            isRecording = false;
            audioChunks = [];
            transcriptionText = "";
            document.getElementById("transcription").innerText = "";
            document.getElementById("audioPlayer").src = "";
            document.getElementById("recordedAudioContainer").style.display = "none";
            document.getElementById("generateAudio").disabled = true;
            document.getElementById("chagpt_audio").style.display = "none";
        }

        async function startRecording() {
            reset_state();
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: true
                });

                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {

                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audioPlayer = document.getElementById('recordedAudioPlayer');
                    audioPlayer.src = audioUrl;
                    document.getElementById('recordedAudioContainer').style.display = 'block';
                    audioPlayer.load();
                };

                // Start recording
                mediaRecorder.start();



                // Create audio context
                audioContext = new AudioContext({
                    sampleRate: 16000
                });

                // Create source from stream
                input = audioContext.createMediaStreamSource(stream);

                // Create processor node
                processor = audioContext.createScriptProcessor(1024, 1, 1);

                // Connect nodes
                input.connect(processor);
                processor.connect(audioContext.destination);



                // Process audio data
                processor.onaudioprocess = (e) => {
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        // Convert Float32Array to Int16Array for better compatibility
                        const int16Data = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            const s = Math.max(-1, Math.min(1, inputData[i]));
                            int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        const message = JSON.stringify({
                            audio: btoa(String.fromCharCode.apply(null, new Uint8Array(int16Data.buffer)))
                        });
                        websocket.send(message);
                    }
                };

                document.getElementById("startRecording").disabled = true;
                document.getElementById("stopRecording").disabled = false;
                document.getElementById('recordingSkeleton').style.display = 'block';
                document.getElementById("generateAudio").disabled = false;
            } catch (error) {
                console.error("Error starting recording:", error);
                alert("Error starting recording. Please make sure you have a microphone connected.");
            }
        }



        function stopRecording() {
            mediaRecorder.stop()
            if (processor && input) {
                processor.disconnect();
                input.disconnect();
                if (audioContext) {
                    audioContext.close();
                }
            }

            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ isFinal: true }));
            }

            document.getElementById("startRecording").disabled = false;
            document.getElementById("stopRecording").disabled = true;
            document.getElementById('recordingSkeleton').style.display = 'none';


        }

        async function generateAudio() {
            const query = encodeURIComponent(transcriptionText);
            const response = await fetch(`/stream-audio/?query=${query}`);
            const audioBlob = await response.blob();
            const audioURL = URL.createObjectURL(audioBlob);
            document.getElementById('audioPlayer').src = audioURL;
            document.getElementById("chagpt_audio").style.display = "block";
            const audioPlayer = document.getElementById('audioPlayer');
            audioPlayer.load();
            audioPlayer.play();

        }

        // Initialize WebSocket on page load
        initWebSocket();
    </script>
</body>

</html>
